{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "from math import sqrt\n",
    "\n",
    "class MyKMeans():\n",
    "    def __init__(self, nr_centroizi) -> None:\n",
    "        self.nr_centroizi = nr_centroizi\n",
    "        self.centroizi = []\n",
    "\n",
    "    def initialize_centroizi(self, input):\n",
    "        index = [i for i in range(input.shape[0])]\n",
    "        indexes = choice(index, self.nr_centroizi)\n",
    "        self.centroizi = [input[i] for i in indexes]\n",
    "\n",
    "    def distance(self, v1, v2):\n",
    "        values = [(v1[0,i] - v2[0,i])*(v1[0,i] - v2[0,i])for i in range(v1.shape[1])]\n",
    "        return sqrt(sum(values))\n",
    "\n",
    "    def minimum_centroid_index(self, x):\n",
    "        indice = 0\n",
    "        minim_distance = self.distance(x,self.centroizi[indice])\n",
    "        for i in range(len(self.centroizi)):\n",
    "            distance = self.distance(x,self.centroizi[i])\n",
    "            if distance < minim_distance:\n",
    "                minim_distance = distance\n",
    "                indice = i\n",
    "        \n",
    "        return indice\n",
    "    \n",
    "    def _upper_sum(self, input, c, j):\n",
    "        return sum([input[i] for i in range(input.shape[0]) if c[i] == j])\n",
    "    \n",
    "    def _lowwer_sum(self, c, j):\n",
    "        return sum([1 for i in range(len(c)) if c[i] == j])\n",
    "\n",
    "    def train(self, training_input):\n",
    "        self.initialize_centroizi(training_input)\n",
    "\n",
    "        convergent = False\n",
    "\n",
    "        while not convergent:\n",
    "            c = []\n",
    "            for i in range(training_input.shape[0]):\n",
    "                x = training_input[i]\n",
    "                indice = self.minimum_centroid_index(x)\n",
    "                c.append(indice)\n",
    "\n",
    "            max_change = -1\n",
    "            for j in range(0, self.nr_centroizi):\n",
    "                new_centroid = self._upper_sum(training_input,c,j) / self._lowwer_sum(c,j)\n",
    "                distance = self.distance(self.centroizi[j],new_centroid)\n",
    "                if distance > max_change:\n",
    "                    max_change = distance\n",
    "                self.centroizi[j]=new_centroid\n",
    "\n",
    "            if max_change < 0.04:\n",
    "                convergent = True\n",
    "        \n",
    "    def predict(self, input):\n",
    "        indexes = [self.minimum_centroid_index(x) for x in input]\n",
    "        return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datas(file_path:str):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def get_training_and_validation_datas(df: pd.DataFrame, training_size = 0.8):\n",
    "    data_size = df.shape[0]\n",
    "    indexes = [i for i in range(data_size)]\n",
    "    training_index = np.random.choice(indexes,int(data_size*training_size))\n",
    "    validation_index = [i for i in range(data_size) if not i in training_index]\n",
    "    training_input = [df['Text'].iloc[index] for index in training_index]\n",
    "    training_output = [df['Sentiment'].iloc[index] for index in training_index]\n",
    "    validation_input = [df['Text'].iloc[index] for index in validation_index]\n",
    "    validation_output = [df['Sentiment'].iloc[index] for index in validation_index]\n",
    "    return training_input, training_output, validation_input, validation_output\n",
    "\n",
    "def get_TP_TN_FP_FN(computed_output, ground_truth, positive_label):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for i in range(len(computed_output)):\n",
    "        if computed_output[i] == positive_label:\n",
    "            if ground_truth[i] == positive_label:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if ground_truth[i] == positive_label:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def get_accuracy(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "def get_precision(TP, TN, FP, FN):\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def get_recall(TP, TN, FP, FN):\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bags_of_words(training_input, validation_input):\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_features = vectorizer.fit_transform(training_input)\n",
    "    validation_features = vectorizer.transform(validation_input)\n",
    "    return train_features, validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(training_input, number_of_clusters:int):\n",
    "    unsupervisedClassifier = MyKMeans(nr_centroizi=number_of_clusters)\n",
    "    unsupervisedClassifier.train(training_input)\n",
    "    return unsupervisedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier:MyKMeans,validation_input, validation_output, label_names,positive_label):\n",
    "    computedTestIndexes = classifier.predict(validation_input)\n",
    "    computed_outputs = [label_names[value] for value in computedTestIndexes]\n",
    "    TP, TN, FP, FN = get_TP_TN_FP_FN(computed_outputs,validation_output,positive_label)\n",
    "    accuracy = get_accuracy(TP, TN, FP, FN)\n",
    "    precision = get_precision(TP, TN, FP, FN)\n",
    "    recall = get_recall(TP, TN, FP, FN)\n",
    "    print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3010752688172043\n",
      "Precision: 0.29347826086956524\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataframe = read_datas('reviews_mixed.csv')\n",
    "training_input,training_output,validation_input, validation_output = get_training_and_validation_datas(dataframe)\n",
    "test_feats, validation_feats = get_bags_of_words(training_input,validation_input)\n",
    "label_names = [name for name in set(training_output)]\n",
    "classifier = get_classifier(test_feats,len(label_names))\n",
    "test_classifier(classifier,validation_feats,validation_output,label_names,'positive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
