{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np \n",
    "from sklearn import neural_network\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TP_TN_FP_FN(truth,computed,positive_label):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for i in range(len(truth)):\n",
    "        if computed[i] == positive_label:\n",
    "            if truth[i] == positive_label:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if truth[i] == positive_label:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "    return TP,TN,FP,FN\n",
    "\n",
    "def getAccuracy(TP,TN,FP,FN):\n",
    "    if TP+TN+FP+FN == 0:\n",
    "        return 0\n",
    "    return (TP + TN) / (TP+TN+FP+FN)\n",
    "\n",
    "def getPrecision(TP,TN,FP,FN):\n",
    "    if TP + FP == 0:\n",
    "        return 0\n",
    "    return TP/(TP + FP)\n",
    "\n",
    "def getRecall(TP,TN,FP,FN):\n",
    "    if TP+FN == 0:\n",
    "        return 0\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datas() -> pd.DataFrame:\n",
    "    df = pd.read_csv('datas.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingAndValidationDatas():\n",
    "    np.random.seed(5)\n",
    "    df = read_datas()\n",
    "    n = df.shape[0]\n",
    "    indexes = [i for i in range(n)]\n",
    "    trainingIndexes = np.random.choice(indexes, int(0.7 * n), replace = False)\n",
    "    validationIndexes = [i for i in range(n) if not i in trainingIndexes]\n",
    "\n",
    "    trainingInputs = [df['Photo'].iloc[i] for i in trainingIndexes]\n",
    "    trainingOutputs = [df['Has Filter'].iloc[i] for i in trainingIndexes]\n",
    "\n",
    "    validationInputs = [df['Photo'].iloc[i] for i in validationIndexes]\n",
    "    validationOutputs = [df['Has Filter'].iloc[i] for i in validationIndexes]\n",
    "\n",
    "    return trainingInputs, trainingOutputs, validationInputs, validationOutputs\n",
    "\n",
    "def getInputParameters(inputImages, size):\n",
    "    params = []\n",
    "    for imagePath in inputImages:\n",
    "        params.append([])\n",
    "        image = Image.open(imagePath)\n",
    "        image = image.resize(size)\n",
    "        for pixel in list(image.getdata()):\n",
    "            r, g, b = pixel[0], pixel[1], pixel[2]\n",
    "            params[-1].append(r)\n",
    "            params[-1].append(g)\n",
    "            params[-1].append(b)\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineClassifier(hidden_layer, activation_function, trainInputs, trainOutputs):\n",
    "    classifier = neural_network.MLPClassifier(hidden_layer_sizes=(hidden_layer,), activation=activation_function, max_iter=100, solver='sgd', verbose=10, random_state=1, learning_rate_init=.1)\n",
    "    classifier.fit(trainInputs, trainOutputs)\n",
    "    return classifier\n",
    "\n",
    "def testClassifier(hidden_layer,activation_function,size):\n",
    "    trainingInputSet, trainingOutputSet, validationInputSet, validationOutputSet = getTrainingAndValidationDatas()\n",
    "    trainInputs = getInputParameters(trainingInputSet, size)\n",
    "    trainOutputs = trainingOutputSet\n",
    "    classifier = defineClassifier(hidden_layer, activation_function, trainInputs, trainOutputs)\n",
    "\n",
    "    validationInputs = getInputParameters(validationInputSet, size)\n",
    "    outputs = classifier.predict(validationInputs)\n",
    "    TP,TN,FP,FN = get_TP_TN_FP_FN(validationOutputSet, outputs,'YES')\n",
    "    acc = getAccuracy(TP,TN,FP,FN)\n",
    "    pr = getPrecision(TP,TN,FP,FN)\n",
    "    re = getRecall(TP,TN,FP,FN)\n",
    "    print(\"Accuracy: {}\\nPrecision: {}\\nRecall: {}\".format(acc,pr,re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.70778898\n",
      "Iteration 2, loss = 0.74905773\n",
      "Iteration 3, loss = 0.73851225\n",
      "Iteration 4, loss = 0.71609072\n",
      "Iteration 5, loss = 0.70337733\n",
      "Iteration 6, loss = 0.68988153\n",
      "Iteration 7, loss = 0.67822156\n",
      "Iteration 8, loss = 0.66700212\n",
      "Iteration 9, loss = 0.65875862\n",
      "Iteration 10, loss = 0.64818881\n",
      "Iteration 11, loss = 0.63938426\n",
      "Iteration 12, loss = 0.63259722\n",
      "Iteration 13, loss = 0.62680634\n",
      "Iteration 14, loss = 0.62183166\n",
      "Iteration 15, loss = 0.61754836\n",
      "Iteration 16, loss = 0.61383912\n",
      "Iteration 17, loss = 0.61061695\n",
      "Iteration 18, loss = 0.60779903\n",
      "Iteration 19, loss = 0.60531744\n",
      "Iteration 20, loss = 0.60311425\n",
      "Iteration 21, loss = 0.60114260\n",
      "Iteration 22, loss = 0.59936483\n",
      "Iteration 23, loss = 0.59775120\n",
      "Iteration 24, loss = 0.59627839\n",
      "Iteration 25, loss = 0.59492801\n",
      "Iteration 26, loss = 0.59368547\n",
      "Iteration 27, loss = 0.59253887\n",
      "Iteration 28, loss = 0.59147829\n",
      "Iteration 29, loss = 0.59049516\n",
      "Iteration 30, loss = 0.58958187\n",
      "Iteration 31, loss = 0.58873147\n",
      "Iteration 32, loss = 0.58793758\n",
      "Iteration 33, loss = 0.58719426\n",
      "Iteration 34, loss = 0.58649599\n",
      "Iteration 35, loss = 0.58583772\n",
      "Iteration 36, loss = 0.58521483\n",
      "Iteration 37, loss = 0.58462319\n",
      "Iteration 38, loss = 0.58405913\n",
      "Iteration 39, loss = 0.58351949\n",
      "Iteration 40, loss = 0.58300156\n",
      "Iteration 41, loss = 0.58250308\n",
      "Iteration 42, loss = 0.58202218\n",
      "Iteration 43, loss = 0.58155735\n",
      "Iteration 44, loss = 0.58110739\n",
      "Iteration 45, loss = 0.58067135\n",
      "Iteration 46, loss = 0.58024850\n",
      "Iteration 47, loss = 0.57983824\n",
      "Iteration 48, loss = 0.57944011\n",
      "Iteration 49, loss = 0.57905372\n",
      "Iteration 50, loss = 0.57867874\n",
      "Iteration 51, loss = 0.57831485\n",
      "Iteration 52, loss = 0.57796176\n",
      "Iteration 53, loss = 0.57761915\n",
      "Iteration 54, loss = 0.57728670\n",
      "Iteration 55, loss = 0.57696409\n",
      "Iteration 56, loss = 0.57665097\n",
      "Iteration 57, loss = 0.57634698\n",
      "Iteration 58, loss = 0.57605174\n",
      "Iteration 59, loss = 0.57576488\n",
      "Iteration 60, loss = 0.57548603\n",
      "Iteration 61, loss = 0.57521482\n",
      "Iteration 62, loss = 0.57495088\n",
      "Iteration 63, loss = 0.57469386\n",
      "Iteration 64, loss = 0.57444342\n",
      "Iteration 65, loss = 0.57419924\n",
      "Iteration 66, loss = 0.57396102\n",
      "Iteration 67, loss = 0.57372848\n",
      "Iteration 68, loss = 0.57350134\n",
      "Iteration 69, loss = 0.57327937\n",
      "Iteration 70, loss = 0.57306233\n",
      "Iteration 71, loss = 0.57285000\n",
      "Iteration 72, loss = 0.57264220\n",
      "Iteration 73, loss = 0.57243873\n",
      "Iteration 74, loss = 0.57223942\n",
      "Iteration 75, loss = 0.57204411\n",
      "Iteration 76, loss = 0.57185265\n",
      "Iteration 77, loss = 0.57166490\n",
      "Iteration 78, loss = 0.57148072\n",
      "Iteration 79, loss = 0.57129998\n",
      "Iteration 80, loss = 0.57112257\n",
      "Iteration 81, loss = 0.57094836\n",
      "Iteration 82, loss = 0.57077725\n",
      "Iteration 83, loss = 0.57060913\n",
      "Iteration 84, loss = 0.57044390\n",
      "Iteration 85, loss = 0.57028146\n",
      "Iteration 86, loss = 0.57012173\n",
      "Iteration 87, loss = 0.56996462\n",
      "Iteration 88, loss = 0.56981003\n",
      "Iteration 89, loss = 0.56965790\n",
      "Iteration 90, loss = 0.56950814\n",
      "Iteration 91, loss = 0.56936068\n",
      "Iteration 92, loss = 0.56921545\n",
      "Iteration 93, loss = 0.56907239\n",
      "Iteration 94, loss = 0.56893143\n",
      "Iteration 95, loss = 0.56879250\n",
      "Iteration 96, loss = 0.56865556\n",
      "Iteration 97, loss = 0.56852055\n",
      "Iteration 98, loss = 0.56838740\n",
      "Iteration 99, loss = 0.56825608\n",
      "Iteration 100, loss = 0.56812654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37037037037037035\n",
      "Precision: 0.2631578947368421\n",
      "Recall: 0.625\n"
     ]
    }
   ],
   "source": [
    "testClassifier(hidden_layer=50,activation_function='tanh',size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.89642108\n",
      "Iteration 2, loss = 0.63412296\n",
      "Iteration 3, loss = 0.69794357\n",
      "Iteration 4, loss = 0.70072646\n",
      "Iteration 5, loss = 0.63723151\n",
      "Iteration 6, loss = 0.62925079\n",
      "Iteration 7, loss = 0.67682228\n",
      "Iteration 8, loss = 0.65885101\n",
      "Iteration 9, loss = 0.62245201\n",
      "Iteration 10, loss = 0.61761372\n",
      "Iteration 11, loss = 0.61410803\n",
      "Iteration 12, loss = 0.61147288\n",
      "Iteration 13, loss = 0.68786381\n",
      "Iteration 14, loss = 0.68688523\n",
      "Iteration 15, loss = 0.65172629\n",
      "Iteration 16, loss = 0.65254372\n",
      "Iteration 17, loss = 0.65369573\n",
      "Iteration 18, loss = 0.65473163\n",
      "Iteration 19, loss = 0.65558411\n",
      "Iteration 20, loss = 0.65622271\n",
      "Iteration 21, loss = 0.65663998\n",
      "Iteration 22, loss = 0.65684512\n",
      "Iteration 23, loss = 0.65685938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.7037037037037037\n",
      "Precision: 0.5\n",
      "Recall: 0.375\n"
     ]
    }
   ],
   "source": [
    "testClassifier(hidden_layer=50,activation_function='tanh',size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69258056\n",
      "Iteration 2, loss = 0.86183074\n",
      "Iteration 3, loss = 0.80509755\n",
      "Iteration 4, loss = 0.70507995\n",
      "Iteration 5, loss = 0.78384003\n",
      "Iteration 6, loss = 0.73340081\n",
      "Iteration 7, loss = 0.68662217\n",
      "Iteration 8, loss = 0.69051958\n",
      "Iteration 9, loss = 0.69080893\n",
      "Iteration 10, loss = 0.68856233\n",
      "Iteration 11, loss = 0.68789332\n",
      "Iteration 12, loss = 0.68821283\n",
      "Iteration 13, loss = 0.68835754\n",
      "Iteration 14, loss = 0.68832711\n",
      "Iteration 15, loss = 0.68832140\n",
      "Iteration 16, loss = 0.68832545\n",
      "Iteration 17, loss = 0.68829053\n",
      "Iteration 18, loss = 0.68821794\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.125\n"
     ]
    }
   ],
   "source": [
    "testClassifier(hidden_layer=20,activation_function='tanh',size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67825132\n",
      "Iteration 2, loss = 0.67685528\n",
      "Iteration 3, loss = 0.69373578\n",
      "Iteration 4, loss = 0.67655048\n",
      "Iteration 5, loss = 0.67581236\n",
      "Iteration 6, loss = 0.67723380\n",
      "Iteration 7, loss = 0.67412327\n",
      "Iteration 8, loss = 0.66538682\n",
      "Iteration 9, loss = 0.65833123\n",
      "Iteration 10, loss = 0.65297890\n",
      "Iteration 11, loss = 0.64831901\n",
      "Iteration 12, loss = 0.64340737\n",
      "Iteration 13, loss = 0.63819484\n",
      "Iteration 14, loss = 0.63302792\n",
      "Iteration 15, loss = 0.62810734\n",
      "Iteration 16, loss = 0.62341620\n",
      "Iteration 17, loss = 0.61888981\n",
      "Iteration 18, loss = 0.61452019\n",
      "Iteration 19, loss = 0.61033960\n",
      "Iteration 20, loss = 0.60637411\n",
      "Iteration 21, loss = 0.60262844\n",
      "Iteration 22, loss = 0.59909641\n",
      "Iteration 23, loss = 0.59577193\n",
      "Iteration 24, loss = 0.59265084\n",
      "Iteration 25, loss = 0.58972816\n",
      "Iteration 26, loss = 0.58699649\n",
      "Iteration 27, loss = 0.58444663\n",
      "Iteration 28, loss = 0.58206878\n",
      "Iteration 29, loss = 0.57985318\n",
      "Iteration 30, loss = 0.57779016\n",
      "Iteration 31, loss = 0.57587005\n",
      "Iteration 32, loss = 0.57408327\n",
      "Iteration 33, loss = 0.57242046\n",
      "Iteration 34, loss = 0.57087265\n",
      "Iteration 35, loss = 0.56943129\n",
      "Iteration 36, loss = 0.56808831\n",
      "Iteration 37, loss = 0.56683608\n",
      "Iteration 38, loss = 0.56566746\n",
      "Iteration 39, loss = 0.56457580\n",
      "Iteration 40, loss = 0.56355490\n",
      "Iteration 41, loss = 0.56259901\n",
      "Iteration 42, loss = 0.56170284\n",
      "Iteration 43, loss = 0.56086148\n",
      "Iteration 44, loss = 0.56007042\n",
      "Iteration 45, loss = 0.55932552\n",
      "Iteration 46, loss = 0.55862297\n",
      "Iteration 47, loss = 0.55795928\n",
      "Iteration 48, loss = 0.55733124\n",
      "Iteration 49, loss = 0.55673594\n",
      "Iteration 50, loss = 0.55617069\n",
      "Iteration 51, loss = 0.55563304\n",
      "Iteration 52, loss = 0.55512077\n",
      "Iteration 53, loss = 0.55463182\n",
      "Iteration 54, loss = 0.55416433\n",
      "Iteration 55, loss = 0.55371659\n",
      "Iteration 56, loss = 0.55328705\n",
      "Iteration 57, loss = 0.55287428\n",
      "Iteration 58, loss = 0.55247698\n",
      "Iteration 59, loss = 0.55209396\n",
      "Iteration 60, loss = 0.55172414\n",
      "Iteration 61, loss = 0.55136653\n",
      "Iteration 62, loss = 0.55102021\n",
      "Iteration 63, loss = 0.55068435\n",
      "Iteration 64, loss = 0.55035820\n",
      "Iteration 65, loss = 0.55004106\n",
      "Iteration 66, loss = 0.54973229\n",
      "Iteration 67, loss = 0.54943130\n",
      "Iteration 68, loss = 0.54913757\n",
      "Iteration 69, loss = 0.54885059\n",
      "Iteration 70, loss = 0.54856992\n",
      "Iteration 71, loss = 0.54829513\n",
      "Iteration 72, loss = 0.54802586\n",
      "Iteration 73, loss = 0.54776174\n",
      "Iteration 74, loss = 0.54750246\n",
      "Iteration 75, loss = 0.54724772\n",
      "Iteration 76, loss = 0.54699724\n",
      "Iteration 77, loss = 0.54675077\n",
      "Iteration 78, loss = 0.54650808\n",
      "Iteration 79, loss = 0.54626895\n",
      "Iteration 80, loss = 0.54603319\n",
      "Iteration 81, loss = 0.54580061\n",
      "Iteration 82, loss = 0.54557104\n",
      "Iteration 83, loss = 0.54534432\n",
      "Iteration 84, loss = 0.54512031\n",
      "Iteration 85, loss = 0.54489887\n",
      "Iteration 86, loss = 0.54467988\n",
      "Iteration 87, loss = 0.54446322\n",
      "Iteration 88, loss = 0.54424879\n",
      "Iteration 89, loss = 0.54403648\n",
      "Iteration 90, loss = 0.54382619\n",
      "Iteration 91, loss = 0.54361786\n",
      "Iteration 92, loss = 0.54341138\n",
      "Iteration 93, loss = 0.54320669\n",
      "Iteration 94, loss = 0.54300373\n",
      "Iteration 95, loss = 0.54280241\n",
      "Iteration 96, loss = 0.54260269\n",
      "Iteration 97, loss = 0.54240450\n",
      "Iteration 98, loss = 0.54220779\n",
      "Iteration 99, loss = 0.54201251\n",
      "Iteration 100, loss = 0.54181863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "Precision: 0.2916666666666667\n",
      "Recall: 0.875\n"
     ]
    }
   ],
   "source": [
    "testClassifier(hidden_layer=30,activation_function='logistic',size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.72448364\n",
      "Iteration 2, loss = 0.80599686\n",
      "Iteration 3, loss = 1.59612458\n",
      "Iteration 4, loss = 2.34971946\n",
      "Iteration 5, loss = 0.69388844\n",
      "Iteration 6, loss = 0.71640782\n",
      "Iteration 7, loss = 1.26075462\n",
      "Iteration 8, loss = 2.34899287\n",
      "Iteration 9, loss = 0.69670056\n",
      "Iteration 10, loss = 0.81892341\n",
      "Iteration 11, loss = 1.91818961\n",
      "Iteration 12, loss = 2.27393850\n",
      "Iteration 13, loss = 0.71349925\n",
      "Iteration 14, loss = 1.01970359\n",
      "Iteration 15, loss = 2.23630351\n",
      "Iteration 16, loss = 1.97561961\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.2962962962962963\n",
      "Precision: 0.2962962962962963\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "testClassifier(hidden_layer=200,activation_function='logistic',size=(200,200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
