{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def _apply_conv_layer(self, input_data, num_filters, filter_size, padding='same', activation='relu'):\n",
    "        input_height, input_width = input_data.shape[0], input_data.shape[1]\n",
    "        output_height = input_height if padding == 'same' else input_height - filter_size[0] + 1\n",
    "        output_width = input_width if padding == 'same' else input_width - filter_size[1] + 1\n",
    "        conv_output = np.zeros((output_height, output_width, num_filters))\n",
    "\n",
    "        # Loop prin fiecare filtru\n",
    "        for f in range(num_filters):\n",
    "            # Loop prin fiecare poziție în imagine\n",
    "            for h in range(output_height):\n",
    "                for w in range(output_width):\n",
    "                    # Extrage fereastra din imagine\n",
    "                    window = input_data[h:h+filter_size[0], w:w+filter_size[1], :]\n",
    "\n",
    "                   \n",
    "                    conv_output[h, w, f] = np.max(window)\n",
    "\n",
    "        # Aplică activarea\n",
    "        if activation == 'relu':\n",
    "            conv_output = np.maximum(conv_output, 0)\n",
    "\n",
    "        return conv_output  # Returnează rezultatul \n",
    "\n",
    "    def _apply_maxpool_layer(self, input_data, pool_size, strides):\n",
    "        input_height, input_width, input_channels = input_data.shape\n",
    "        output_height = (input_height - pool_size[0]) // strides[0] + 1\n",
    "        output_width = (input_width - pool_size[1]) // strides[1] + 1\n",
    "        pool_output = np.zeros((output_height, output_width, input_channels))\n",
    "\n",
    "        for h in range(0, input_height - pool_size[0] + 1, strides[0]):\n",
    "            for w in range(0, input_width - pool_size[1] + 1, strides[1]):\n",
    "                window = input_data[h:h+pool_size[0], w:w+pool_size[1], :]\n",
    "                for c in range(input_channels):\n",
    "                    pool_output[h // strides[0], w // strides[1], c] = np.max(window[:, :, c])\n",
    "\n",
    "        return pool_output\n",
    "\n",
    "    def _apply_fc_layer(self, input_data, num_units, activation='relu'):\n",
    "        input_size = np.prod(input_data.shape)\n",
    "        input_data_flat = input_data.flatten()\n",
    "        weights = np.random.randn(input_size, num_units)\n",
    "        fc_output = np.dot(input_data_flat, weights)\n",
    "\n",
    "        if activation == 'relu':\n",
    "            fc_output = np.maximum(fc_output, 0)\n",
    "\n",
    "        return fc_output\n",
    " \n",
    "    def add_conv_layer(self, num_filters, filter_size, input_channels, padding='same', activation='relu'):\n",
    "        weights_shape = (*filter_size, input_channels, num_filters)\n",
    "        weights = np.random.randn(*weights_shape)\n",
    "        layer = {'type': 'conv', 'num_filters': num_filters, 'filter_size': filter_size, 'input_channels': input_channels, 'padding': padding, 'activation': activation, 'weights': weights}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def add_maxpool_layer(self, pool_size, strides):\n",
    "        layer = {'type': 'maxpool', 'pool_size': pool_size, 'strides': strides}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def add_fc_layer(self, num_units, input_shape=None, weights=None, activation='relu'):\n",
    "        if weights is None:\n",
    "            if input_shape is None:\n",
    "                raise ValueError(\"Input shape must be provided if weights are not specified.\")\n",
    "            input_size = np.prod(input_shape)\n",
    "            weights = np.random.randn(input_size, num_units)\n",
    "        layer = {'type': 'fc', 'num_units': num_units, 'activation': activation, 'weights': weights}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def _apply_layer(self, layer, input_data):\n",
    "        if layer['type'] == 'conv':\n",
    "            return self._apply_conv_layer(input_data, layer['num_filters'], layer['filter_size'], layer['padding'], layer['activation'])\n",
    "        elif layer['type'] == 'maxpool':\n",
    "            return self._apply_maxpool_layer(input_data, layer['pool_size'], layer['strides'])\n",
    "        elif layer['type'] == 'fc':\n",
    "            return self._apply_fc_layer(input_data, layer['num_units'], layer['activation'])\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate=0.001, epochs=10, batch_size=1):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                batch_X = X_train[i:i+batch_size]\n",
    "                batch_y = y_train[i:i+batch_size]  # Assuming y_train is already in the format [1, 0] or [0, 1]\n",
    "                batch_y = np.expand_dims(batch_y, axis=(1, 2))  # Add dummy dimensions to match input_data shape\n",
    "\n",
    "\n",
    "\n",
    "                # Forward pass\n",
    "                input_data = batch_X\n",
    "                for layer in self.layers:\n",
    "                    input_data = self._apply_layer(layer, input_data)\n",
    "                grad_output = 2 * (input_data - batch_y)  # Gradientul funcției de pierdere (MSE)\n",
    "                for layer in reversed(self.layers):\n",
    "                    if layer['type'] == 'conv' or layer['type'] == 'fc':\n",
    "                        grad_input, grad_weights = self._backward_layer(layer, input_data, grad_output)\n",
    "                        layer['gradient_weights'] = grad_weights\n",
    "                        input_data = grad_input  # Actualizăm input_data pentru layer-ul anterior\n",
    "                        # Actualizarea ponderilor folosind gradient descent\n",
    "                        if 'weights' in layer:\n",
    "                            layer['weights'] -= learning_rate * layer['gradient_weights']\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: \")  # Afișăm loss-ul sau metrica de evaluare la finalul fiecărei epoci\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.apply_layers(X_test)\n",
    "        accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    def apply_layers(self, input_data):\n",
    "        for layer in self.layers:\n",
    "            input_data = self._apply_layer(layer, input_data)\n",
    "        return input_data\n",
    "\n",
    "    def _backward_layer(self, layer, input_data, grad_output):\n",
    "        if layer['type'] == 'conv':\n",
    "            return self._conv_backward(layer, input_data, grad_output)\n",
    "        elif layer['type'] == 'fc':\n",
    "            return self._fc_backward(layer, input_data, grad_output)\n",
    "\n",
    "    def _conv_backward(self, layer, input_data, grad_output):\n",
    "        grad_input = np.zeros_like(input_data)\n",
    "        grad_weights = np.zeros_like(layer['weights'])\n",
    "\n",
    "        for i in range(layer['num_filters']):\n",
    "            for j in range(grad_output.shape[0]):\n",
    "                print(layer['weights'][i])\n",
    "                print(grad_output[i])\n",
    "                grad_input[j] += np.rot90(layer['weights'][i], 2) @ grad_output[i]\n",
    "                grad_weights[i] += np.rot90(input_data[j], 2) @ grad_output[i]\n",
    "\n",
    "        return grad_input, grad_weights\n",
    "\n",
    "    def _fc_backward(self, layer, input_data, grad_output):\n",
    "        grad_input = grad_output @ layer['weights'].T\n",
    "        grad_weights = input_data @ grad_output.T\n",
    "\n",
    "        return grad_input, grad_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmath import exp\n",
    "\n",
    "class ConvNeuralNetwork():\n",
    "    def __init__(self) -> None:\n",
    "        self.filters = []\n",
    "\n",
    "    def add_conv_layer(self,num_filters: int,filter_size: tuple):\n",
    "        h,w = filter_size\n",
    "        filter = [[np.random.randn() for _ in range(w)] for _ in range(h)]\n",
    "        self.filters.append({'type': 'conv', 'num_filters': num_filters,'size': filter_size, 'filter': filter})\n",
    "    \n",
    "    def add_maxpool_layer(self,size:tuple):\n",
    "        self.filters.append({'type': 'maxpool','size': size})\n",
    "    \n",
    "    def add_fully_connected_layer(self,input_size: int, ouput_size: int):\n",
    "        weights = [[np.random.randn() for _ in range(input_size)] for _ in range(ouput_size)]\n",
    "        self.filters.append({'type': 'fully connected','weights':weights})\n",
    "    \n",
    "    def _apply_conv_layer(self,input, layer: dict):\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        filter = layer['filter']\n",
    "        filter_size = layer['size']\n",
    "        num_filters = layer['num_filters']\n",
    "\n",
    "        start_i = filter_size[0] // 2\n",
    "        final_i = height - filter_size[0] // 2\n",
    "        start_j = filter_size[1] // 2\n",
    "        final_j = width - filter_size[1] // 2\n",
    "\n",
    "        result = []\n",
    "        for i in range(start_i, final_i):\n",
    "            result.append([])\n",
    "            for j in range(start_j, final_j):\n",
    "                result[-1].append([])\n",
    "                for _ in range(num_filters):\n",
    "                    for k in range(depth):\n",
    "                        s = 0\n",
    "                        for h in range(filter_size[0]):\n",
    "                            for w in range(filter_size[1]):\n",
    "                                s += filter[h][w]*input[i+h-filter_size[0]//2][j+w-filter_size[1]//2][k]\n",
    "                        \n",
    "                        result[i-start_i][j-start_j].append(s)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _apply_maxpool_layer(self, input, layer):\n",
    "        h, w = layer['size']\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        result = []\n",
    "        for i in range(0, height - h + 1, h):\n",
    "            result.append([])\n",
    "            for j in range(0, width - w + 1, w):\n",
    "                result[-1].append([])\n",
    "                for k in range(depth):\n",
    "                    values = []\n",
    "                    for row in range(i,i+h):\n",
    "                        for col in range(j,j+w):\n",
    "                            values.append(input[row][col][k])\n",
    "                    result[-1][-1].append(max(values))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _linear_input(self, input):\n",
    "        result = []\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                for k in range(depth):\n",
    "                    result.append(input[i][j][k])\n",
    "        return result\n",
    "\n",
    "    def _apply_fully_connected_layer(self, input, layer):\n",
    "        lin_input = self._linear_input(input)\n",
    "        weights = layer['weights']\n",
    "        sigmoid = lambda x : 1 / (1 + exp(-x).real)\n",
    "        results = []\n",
    "        for w in weights:\n",
    "            val = sum([w[i] * lin_input[i] for i in range(len(w))])\n",
    "            s = sigmoid(val)\n",
    "            results.append(s)\n",
    "        return results\n",
    "\n",
    "    def _apply_layer(self, input, layer):\n",
    "        type = layer['type']\n",
    "        if type == 'conv':\n",
    "            return self._apply_conv_layer(input, layer)\n",
    "        elif type == 'maxpool':\n",
    "            return self._apply_maxpool_layer(input, layer)\n",
    "        elif type == 'fully connected':\n",
    "            return self._apply_fully_connected_layer(input, layer)\n",
    "\n",
    "    def _back_propagation_fully_connected_layer(self,layer,errors, input_line):\n",
    "        learning_rate = 0.00000001\n",
    "        for i in range(0,len(errors)):\n",
    "            err = errors[i]\n",
    "            r = input_line\n",
    "            for l in self.filters[:-1]:\n",
    "                r = self._apply_layer(r,l)\n",
    "            r = self._linear_input(r)\n",
    "            for j in range(len(r)):\n",
    "                layer['weights'][i][j] = layer['weights'][i][j] - learning_rate * err * r[j]\n",
    "\n",
    "    def _back_propagation_conv_layer(self, layer, errors):\n",
    "        learning_rate = 0.00000001\n",
    "        for i in range(0, len(errors)):\n",
    "            filter = layer['filter']\n",
    "            for k1 in range(len(filter)):\n",
    "                for k2 in range(len(filter[k1])):\n",
    "                    layer['filter'][k1][k2] = layer['filter'][k1][k2] - errors[i]*learning_rate\n",
    "            \n",
    "    def _back_propagation(self, errors, input_line):\n",
    "        for layer in reversed(self.filters):\n",
    "            type = layer['type']\n",
    "            if type == 'fully connected':\n",
    "                self._back_propagation_fully_connected_layer(layer, errors, input_line)\n",
    "            if type == 'conv':\n",
    "                self._back_propagation_conv_layer(layer,errors)\n",
    "\n",
    "    def _apply_layers(self, input_line):\n",
    "        result = input_line\n",
    "        for layer in self.filters:\n",
    "            result = self._apply_layer(result, layer)\n",
    "        return result\n",
    "\n",
    "    def train(self, input, output, epoch):\n",
    "        for e in range(epoch):\n",
    "            print(f\"Start epoch {e}\")\n",
    "            for i in range(len(input)):\n",
    "                input_line = input[i]\n",
    "                o = output[i]\n",
    "                result = self._apply_layers(input_line)\n",
    "                yes_prob = result[0]\n",
    "                no_prob = result[1]\n",
    "                if o == 'YES':\n",
    "                    err = [1-yes_prob, 0-no_prob]\n",
    "                else:\n",
    "                    err = [0-yes_prob, 1-no_prob]\n",
    "                \n",
    "                self._back_propagation(err,input_line)\n",
    "\n",
    "    def predict(self,input):\n",
    "        output = []\n",
    "        for input_line in input:\n",
    "            result = self._apply_layers(input_line)\n",
    "            if result[0] > result[1]:\n",
    "                output.append('YES')\n",
    "            else:\n",
    "                output.append('NO')\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n",
      "Start epoch 1\n",
      "Start epoch 2\n",
      "Start epoch 3\n",
      "Start epoch 4\n",
      "Start epoch 5\n",
      "Start epoch 6\n",
      "Start epoch 7\n",
      "Start epoch 8\n",
      "Start epoch 9\n",
      "YES NO\n",
      "YES NO\n",
      "NO NO\n",
      "NO NO\n",
      "NO NO\n",
      "NO NO\n",
      "YES NO\n",
      "NO NO\n",
      "YES NO\n",
      "NO NO\n",
      "NO NO\n",
      "NO YES\n",
      "NO YES\n",
      "NO YES\n",
      "NO YES\n",
      "NO NO\n",
      "NO YES\n",
      "YES NO\n",
      "NO NO\n",
      "NO NO\n",
      "YES NO\n",
      "NO NO\n",
      "NO NO\n",
      "NO NO\n",
      "NO YES\n",
      "NO YES\n",
      "NO YES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ConvNeuralNetwork at 0x7fe5b37de9e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def read_datas() -> pd.DataFrame:\n",
    "    df = pd.read_csv('datas.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "def getTrainingAndValidationDatas():\n",
    "    np.random.seed(5)\n",
    "    df = read_datas()\n",
    "    n = df.shape[0]\n",
    "    indexes = [i for i in range(n)]\n",
    "    trainingIndexes = np.random.choice(indexes, int(0.7 * n), replace = False)\n",
    "    validationIndexes = [i for i in range(n) if not i in trainingIndexes]\n",
    "\n",
    "    trainingInputs = [df['Photo'].iloc[i] for i in trainingIndexes]\n",
    "    trainingOutputs = [df['Has Filter'].iloc[i] for i in trainingIndexes]\n",
    "\n",
    "    validationInputs = [df['Photo'].iloc[i] for i in validationIndexes]\n",
    "    validationOutputs = [df['Has Filter'].iloc[i] for i in validationIndexes]\n",
    "\n",
    "    return trainingInputs, trainingOutputs, validationInputs, validationOutputs\n",
    "\n",
    "def getInputParameters(inputImages, size):\n",
    "    params = []\n",
    "    for imagePath in inputImages:\n",
    "        params.append([])\n",
    "        image = Image.open(imagePath)\n",
    "        image = image.resize(size)\n",
    "        width, height = image.size\n",
    "        pixel_data = list(image.getdata())\n",
    "        for y in range(height):\n",
    "            row_pixels = pixel_data[y * width : (y + 1) * width]\n",
    "            params[-1].append([])\n",
    "            for pixel in row_pixels:\n",
    "                r,g,b = pixel[0],pixel[1],pixel[2]\n",
    "                maxi = max([r,g,b])\n",
    "                mini = min([r,g,b])\n",
    "                if mini == maxi:\n",
    "                    r = g = b = 0\n",
    "                else:\n",
    "                    r = (r-mini)/(maxi-mini)\n",
    "                    g = (g-mini)/(maxi-mini)\n",
    "                    b = (b-mini)/(maxi-mini)\n",
    "                params[-1][-1].append([r,g,b])\n",
    "    return params\n",
    "\n",
    "def getClassifier():\n",
    "    trainingInputs, trainingOutputs, validationInputs, validationOutputs = getTrainingAndValidationDatas()\n",
    "    x_train = getInputParameters(trainingInputs,(62,62))\n",
    "    x_valid = getInputParameters(validationInputs,(62,62))\n",
    "    cnn = ConvNeuralNetwork()\n",
    "    cnn.add_conv_layer(3,(3,3))\n",
    "    cnn.add_maxpool_layer((4,4))\n",
    "    cnn.add_fully_connected_layer(input_size=15*15*9,ouput_size=2)\n",
    "    cnn.train(x_train, trainingOutputs,10)\n",
    "\n",
    "    outut = cnn.predict(x_valid)\n",
    "\n",
    "    for o,vo in zip(outut, validationOutputs):\n",
    "        print(o,vo)\n",
    "\n",
    "    return cnn\n",
    "\n",
    "getClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
