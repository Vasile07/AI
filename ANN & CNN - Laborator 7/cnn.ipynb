{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def _apply_conv_layer(self, input_data, num_filters, filter_size, padding='same', activation='relu'):\n",
    "        input_height, input_width = input_data.shape[0], input_data.shape[1]\n",
    "        output_height = input_height if padding == 'same' else input_height - filter_size[0] + 1\n",
    "        output_width = input_width if padding == 'same' else input_width - filter_size[1] + 1\n",
    "        conv_output = np.zeros((output_height, output_width, num_filters))\n",
    "\n",
    "        # Loop prin fiecare filtru\n",
    "        for f in range(num_filters):\n",
    "            # Loop prin fiecare poziție în imagine\n",
    "            for h in range(output_height):\n",
    "                for w in range(output_width):\n",
    "                    # Extrage fereastra din imagine\n",
    "                    window = input_data[h:h+filter_size[0], w:w+filter_size[1], :]\n",
    "\n",
    "                   \n",
    "                    conv_output[h, w, f] = np.max(window)\n",
    "\n",
    "        # Aplică activarea\n",
    "        if activation == 'relu':\n",
    "            conv_output = np.maximum(conv_output, 0)\n",
    "\n",
    "        return conv_output  # Returnează rezultatul \n",
    "\n",
    "    def _apply_maxpool_layer(self, input_data, pool_size, strides):\n",
    "        input_height, input_width, input_channels = input_data.shape\n",
    "        output_height = (input_height - pool_size[0]) // strides[0] + 1\n",
    "        output_width = (input_width - pool_size[1]) // strides[1] + 1\n",
    "        pool_output = np.zeros((output_height, output_width, input_channels))\n",
    "\n",
    "        for h in range(0, input_height - pool_size[0] + 1, strides[0]):\n",
    "            for w in range(0, input_width - pool_size[1] + 1, strides[1]):\n",
    "                window = input_data[h:h+pool_size[0], w:w+pool_size[1], :]\n",
    "                for c in range(input_channels):\n",
    "                    pool_output[h // strides[0], w // strides[1], c] = np.max(window[:, :, c])\n",
    "\n",
    "        return pool_output\n",
    "\n",
    "    def _apply_fc_layer(self, input_data, num_units, activation='relu'):\n",
    "        input_size = np.prod(input_data.shape)\n",
    "        input_data_flat = input_data.flatten()\n",
    "        weights = np.random.randn(input_size, num_units)\n",
    "        fc_output = np.dot(input_data_flat, weights)\n",
    "\n",
    "        if activation == 'relu':\n",
    "            fc_output = np.maximum(fc_output, 0)\n",
    "\n",
    "        return fc_output\n",
    " \n",
    "    def add_conv_layer(self, num_filters, filter_size, input_channels, padding='same', activation='relu'):\n",
    "        weights_shape = (*filter_size, input_channels, num_filters)\n",
    "        weights = np.random.randn(*weights_shape)\n",
    "        layer = {'type': 'conv', 'num_filters': num_filters, 'filter_size': filter_size, 'input_channels': input_channels, 'padding': padding, 'activation': activation, 'weights': weights}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def add_maxpool_layer(self, pool_size, strides):\n",
    "        layer = {'type': 'maxpool', 'pool_size': pool_size, 'strides': strides}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def add_fc_layer(self, num_units, input_shape=None, weights=None, activation='relu'):\n",
    "        if weights is None:\n",
    "            if input_shape is None:\n",
    "                raise ValueError(\"Input shape must be provided if weights are not specified.\")\n",
    "            input_size = np.prod(input_shape)\n",
    "            weights = np.random.randn(input_size, num_units)\n",
    "        layer = {'type': 'fc', 'num_units': num_units, 'activation': activation, 'weights': weights}\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def _apply_layer(self, layer, input_data):\n",
    "        if layer['type'] == 'conv':\n",
    "            return self._apply_conv_layer(input_data, layer['num_filters'], layer['filter_size'], layer['padding'], layer['activation'])\n",
    "        elif layer['type'] == 'maxpool':\n",
    "            return self._apply_maxpool_layer(input_data, layer['pool_size'], layer['strides'])\n",
    "        elif layer['type'] == 'fc':\n",
    "            return self._apply_fc_layer(input_data, layer['num_units'], layer['activation'])\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate=0.001, epochs=10, batch_size=1):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                batch_X = X_train[i:i+batch_size]\n",
    "                batch_y = y_train[i:i+batch_size]  # Assuming y_train is already in the format [1, 0] or [0, 1]\n",
    "                batch_y = np.expand_dims(batch_y, axis=(1, 2))  # Add dummy dimensions to match input_data shape\n",
    "\n",
    "\n",
    "\n",
    "                # Forward pass\n",
    "                input_data = batch_X\n",
    "                for layer in self.layers:\n",
    "                    input_data = self._apply_layer(layer, input_data)\n",
    "                grad_output = 2 * (input_data - batch_y)  # Gradientul funcției de pierdere (MSE)\n",
    "                for layer in reversed(self.layers):\n",
    "                    if layer['type'] == 'conv' or layer['type'] == 'fc':\n",
    "                        grad_input, grad_weights = self._backward_layer(layer, input_data, grad_output)\n",
    "                        layer['gradient_weights'] = grad_weights\n",
    "                        input_data = grad_input  # Actualizăm input_data pentru layer-ul anterior\n",
    "                        # Actualizarea ponderilor folosind gradient descent\n",
    "                        if 'weights' in layer:\n",
    "                            layer['weights'] -= learning_rate * layer['gradient_weights']\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: \")  # Afișăm loss-ul sau metrica de evaluare la finalul fiecărei epoci\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.apply_layers(X_test)\n",
    "        accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    def apply_layers(self, input_data):\n",
    "        for layer in self.layers:\n",
    "            input_data = self._apply_layer(layer, input_data)\n",
    "        return input_data\n",
    "\n",
    "    def _backward_layer(self, layer, input_data, grad_output):\n",
    "        if layer['type'] == 'conv':\n",
    "            return self._conv_backward(layer, input_data, grad_output)\n",
    "        elif layer['type'] == 'fc':\n",
    "            return self._fc_backward(layer, input_data, grad_output)\n",
    "\n",
    "    def _conv_backward(self, layer, input_data, grad_output):\n",
    "        grad_input = np.zeros_like(input_data)\n",
    "        grad_weights = np.zeros_like(layer['weights'])\n",
    "\n",
    "        for i in range(layer['num_filters']):\n",
    "            for j in range(grad_output.shape[0]):\n",
    "                print(layer['weights'][i])\n",
    "                print(grad_output[i])\n",
    "                grad_input[j] += np.rot90(layer['weights'][i], 2) @ grad_output[i]\n",
    "                grad_weights[i] += np.rot90(input_data[j], 2) @ grad_output[i]\n",
    "\n",
    "        return grad_input, grad_weights\n",
    "\n",
    "    def _fc_backward(self, layer, input_data, grad_output):\n",
    "        grad_input = grad_output @ layer['weights'].T\n",
    "        grad_weights = input_data @ grad_output.T\n",
    "\n",
    "        return grad_input, grad_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmath import exp\n",
    "\n",
    "class ConvNeuralNetwork():\n",
    "    def __init__(self) -> None:\n",
    "        self.filters = []\n",
    "\n",
    "    def add_conv_layer(self,num_filters: int,filter_size: tuple):\n",
    "        h,w = filter_size\n",
    "        filter = [[np.random.randn() for _ in range(w)] for _ in range(h)]\n",
    "        self.filters.append({'type': 'conv', 'num_filters': num_filters,'size': filter_size, 'filter': filter})\n",
    "    \n",
    "    def add_maxpool_layer(self,size:tuple):\n",
    "        self.filters.append({'type': 'maxpool','size': size})\n",
    "    \n",
    "    def add_fully_connected_layer(self,input_size: int, ouput_size: int):\n",
    "        weights = [[np.random.randn() for _ in range(input_size)] for _ in range(ouput_size)]\n",
    "        self.filters.append({'type': 'fully connected','weights':weights})\n",
    "    \n",
    "    def _apply_conv_layer(self,input, layer: dict):\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        filter = layer['filter']\n",
    "        filter_size = layer['size']\n",
    "        num_filters = layer['num_filters']\n",
    "\n",
    "        start_i = filter_size[0] // 2\n",
    "        final_i = height - filter_size[0] // 2\n",
    "        start_j = filter_size[1] // 2\n",
    "        final_j = width - filter_size[1] // 2\n",
    "\n",
    "        result = []\n",
    "        for i in range(start_i, final_i):\n",
    "            result.append([])\n",
    "            for j in range(start_j, final_j):\n",
    "                result[-1].append([])\n",
    "                for _ in range(num_filters):\n",
    "                    for k in range(depth):\n",
    "                        s = 0\n",
    "                        for h in range(filter_size[0]):\n",
    "                            for w in range(filter_size[1]):\n",
    "                                s += filter[h][w]*input[i+h-filter_size[0]//2][j+w-filter_size[1]//2][k]\n",
    "                        \n",
    "                        result[i-start_i][j-start_j].append(s)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _apply_maxpool_layer(self, input, layer):\n",
    "        h, w = layer['size']\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        result = []\n",
    "        for i in range(0, height - h + 1, h):\n",
    "            result.append([])\n",
    "            for j in range(0, width - w + 1, w):\n",
    "                result[-1].append([])\n",
    "                for k in range(depth):\n",
    "                    values = []\n",
    "                    for row in range(i,i+h):\n",
    "                        for col in range(j,j+w):\n",
    "                            values.append(input[row][col][k])\n",
    "                    result[-1][-1].append(max(values))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _linear_input(self, input):\n",
    "        result = []\n",
    "        width, height, depth = len(input[-1]), len(input), len(input[-1][-1])\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                for k in range(depth):\n",
    "                    result.append(input[i][j][k])\n",
    "        return result\n",
    "\n",
    "    def _apply_fully_connected_layer(self, input, layer):\n",
    "        lin_input = self._linear_input(input)\n",
    "        weights = layer['weights']\n",
    "        sigmoid = lambda x : 1 / (1 + exp(-x).real)\n",
    "        results = []\n",
    "        for w in weights:\n",
    "            s = sigmoid(sum([w[i] * lin_input[i] for i in range(len(w))]))\n",
    "            results.append(s)\n",
    "        return results\n",
    "\n",
    "    def _apply_layer(self, input, layer):\n",
    "        type = layer['type']\n",
    "        if type == 'conv':\n",
    "            return self._apply_conv_layer(input, layer)\n",
    "        elif type == 'maxpool':\n",
    "            return self._apply_maxpool_layer(input, layer)\n",
    "        elif type == 'fully connected':\n",
    "            return self._apply_fully_connected_layer(input, layer)\n",
    "\n",
    "    def _back_propagation_fully_connected_layer(self,layer,errors, input_line):\n",
    "        learning_rate = 0.00000001\n",
    "        for i in range(0,len(errors)):\n",
    "            err = errors[i]\n",
    "            r = input_line\n",
    "            for l in self.filters[:-1]:\n",
    "                r = self._apply_layer(r,l)\n",
    "            r = self._linear_input(r)\n",
    "            for j in range(len(r)):\n",
    "                layer['weights'][i][j] = layer['weights'][i][j] - learning_rate * err * r[j]\n",
    "            \n",
    "    def _back_propagation(self, errors, input_line):\n",
    "        for layer in reversed(self.filters):\n",
    "            type = layer['type']\n",
    "            if type == 'fully connected':\n",
    "                self._back_propagation_fully_connected_layer(layer, errors, input_line)\n",
    "        return None\n",
    "\n",
    "    def _apply_layers(self, input_line):\n",
    "        result = input_line\n",
    "        for layer in self.filters:\n",
    "            result = self._apply_layer(result, layer)\n",
    "        return result\n",
    "\n",
    "    def train(self, input, output, epoch):\n",
    "        for e in range(epoch):\n",
    "            for i in range(len(input)):\n",
    "                input_line = input[i]\n",
    "                o = output[i]\n",
    "                result = self._apply_layers(input_line)\n",
    "                yes_prob = result[0]\n",
    "                no_prob = result[1]\n",
    "                if o == 'YES':\n",
    "                    err = [1-yes_prob, 0-no_prob]\n",
    "                else:\n",
    "                    err = [0-yes_prob, 1-no_prob]\n",
    "                \n",
    "                self._back_propagation(err,input_line)\n",
    "\n",
    "    def predict(input):\n",
    "        output = []\n",
    "        for input_line in input:\n",
    "            result = self._apply_layers(input_line)\n",
    "            if result[0] > result[1]:\n",
    "                output.append('YES')\n",
    "            else:\n",
    "                output.append('NO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     cnn\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn\n\u001b[0;32m---> 69\u001b[0m \u001b[43mgetClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 62\u001b[0m, in \u001b[0;36mgetClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m X_train \u001b[38;5;241m=\u001b[39m getInputParameters(trainingInputs,(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m     61\u001b[0m y_train \u001b[38;5;241m=\u001b[39m trainingOutputs\n\u001b[0;32m---> 62\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m X_test \u001b[38;5;241m=\u001b[39m getInputParameters(validationInputs,(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m))\n\u001b[1;32m     65\u001b[0m y_test \u001b[38;5;241m=\u001b[39m validationOutputs\n",
      "Cell \u001b[0;32mIn[15], line 229\u001b[0m, in \u001b[0;36mCNN.train\u001b[0;34m(self, X_train, y_train, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 229\u001b[0m         grad_input, grad_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m         layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradient_weights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grad_weights\n\u001b[1;32m    231\u001b[0m         input_data \u001b[38;5;241m=\u001b[39m grad_input  \u001b[38;5;66;03m# Use gradient as input for next layer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 256\u001b[0m, in \u001b[0;36mCNN._backward_layer\u001b[0;34m(self, layer, input_data, grad_output)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer, input_data, grad_output):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fc_backward(layer, input_data, grad_output)\n",
      "Cell \u001b[0;32mIn[15], line 265\u001b[0m, in \u001b[0;36mCNN._conv_backward\u001b[0;34m(self, layer, input_data, grad_output)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad_input)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_filters\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 265\u001b[0m     \u001b[43mgrad_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mroll(grad_output[:, :], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mroll(grad_output[:, :], (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grad_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grad_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def read_datas() -> pd.DataFrame:\n",
    "    df = pd.read_csv('datas.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "def getTrainingAndValidationDatas():\n",
    "    np.random.seed(5)\n",
    "    df = read_datas()\n",
    "    n = df.shape[0]\n",
    "    indexes = [i for i in range(n)]\n",
    "    trainingIndexes = np.random.choice(indexes, int(0.7 * n), replace = False)\n",
    "    validationIndexes = [i for i in range(n) if not i in trainingIndexes]\n",
    "\n",
    "    trainingInputs = [df['Photo'].iloc[i] for i in trainingIndexes]\n",
    "    trainingOutputs = [df['Has Filter'].iloc[i] for i in trainingIndexes]\n",
    "\n",
    "    validationInputs = [df['Photo'].iloc[i] for i in validationIndexes]\n",
    "    validationOutputs = [df['Has Filter'].iloc[i] for i in validationIndexes]\n",
    "\n",
    "    return trainingInputs, trainingOutputs, validationInputs, validationOutputs\n",
    "\n",
    "def getInputParameters(inputImages, size):\n",
    "    params = []\n",
    "    for imagePath in inputImages:\n",
    "        params.append([])\n",
    "        image = Image.open(imagePath)\n",
    "        image = image.resize(size)\n",
    "        width, height = image.size\n",
    "        pixel_data = list(image.getdata())\n",
    "        for y in range(height):\n",
    "            row_pixels = pixel_data[y * width : (y + 1) * width]\n",
    "            params[-1].append([])\n",
    "            for pixel in row_pixels:\n",
    "                r,g,b = pixel[0],pixel[1],pixel[2]\n",
    "                params[-1][-1].append([r,g,b])\n",
    "    return params\n",
    "\n",
    "def getClassifier():\n",
    "    trainingInputs, trainingOutputs, validationInputs, validationOutputs\n",
    "    x_train = getInputParameters(trainingInputs,(62,62))\n",
    "    x_valid = getInputParameters(validationInputs,(62,62))\n",
    "    cnn = ConvNeuralNetwork()\n",
    "\n",
    "    return cnn\n",
    "\n",
    "getClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
